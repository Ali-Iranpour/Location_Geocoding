{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import googlemaps\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data from the csv file and modifing this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/ghost/Desktop/TeIAS/RA/RA_Map/Data/universities_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word added to each value in the column and saved to modified_file.csv\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/ghost/Desktop/TeIAS/RA/RA_Map/University/universities_all.csv')\n",
    "\n",
    "# Specify the column you want to modify and the word you want to add\n",
    "column_to_modify = 'full_university_name_modified'  # Replace with your actual column name\n",
    "word_to_add = 'دانشگاه'  # Replace with the word you want to add\n",
    "\n",
    "# Modify the column by adding the word to each value (prepend or append)\n",
    "# To append the word\n",
    "df[column_to_modify] = word_to_add + ' ' + df[column_to_modify].astype(str)\n",
    "\n",
    "# To prepend the word, you can reverse the operation:\n",
    "# df[column_to_modify] = word_to_add + ' ' + df[column_to_modify].astype(str)\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "df.to_csv('modified_file.csv', index=False)\n",
    "\n",
    "print(\"Word added to each value in the column and saved to modified_file.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding duplicates for further cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with duplicate values in the column saved to duplicate_rows.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "duplicate = df[df.duplicated(['latitude', 'longitude'])] \n",
    "# Display or save the rows with duplicate values\n",
    "duplicate.to_csv('duplicate_rows.csv', index=False)\n",
    "\n",
    "print(\"Rows with duplicate values in the column saved to duplicate_rows.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>full university name</th>\n",
       "      <th>university name</th>\n",
       "      <th>branch name</th>\n",
       "      <th>location</th>\n",
       "      <th>full_university_name_modified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>دانشگاه آیت اله بروجردی - بروجرد</td>\n",
       "      <td>دانشگاه آیت اله بروجردی</td>\n",
       "      <td>NaN</td>\n",
       "      <td>بروجرد</td>\n",
       "      <td>آیت اله بروجردی بروجرد</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>دانشگاه آیت اله حایری - میبد</td>\n",
       "      <td>دانشگاه آیت اله حایری</td>\n",
       "      <td>NaN</td>\n",
       "      <td>میبد</td>\n",
       "      <td>آیت اله حایری میبد</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>دانشگاه اراک</td>\n",
       "      <td>دانشگاه اراک</td>\n",
       "      <td>NaN</td>\n",
       "      <td>اراک</td>\n",
       "      <td>اراک</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>دانشگاه اردکان</td>\n",
       "      <td>دانشگاه اردکان</td>\n",
       "      <td>NaN</td>\n",
       "      <td>اردکان</td>\n",
       "      <td>اردکان</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>دانشگاه ارومیه</td>\n",
       "      <td>دانشگاه ارومیه</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ارومیه</td>\n",
       "      <td>ارومیه</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              full university name          university name  \\\n",
       "0           0  دانشگاه آیت اله بروجردی - بروجرد  دانشگاه آیت اله بروجردی   \n",
       "1           1      دانشگاه آیت اله حایری - میبد    دانشگاه آیت اله حایری   \n",
       "2           2                      دانشگاه اراک             دانشگاه اراک   \n",
       "3           3                    دانشگاه اردکان           دانشگاه اردکان   \n",
       "4           4                    دانشگاه ارومیه           دانشگاه ارومیه   \n",
       "\n",
       "  branch name location full_university_name_modified  \n",
       "0         NaN   بروجرد        آیت اله بروجردی بروجرد  \n",
       "1         NaN     میبد            آیت اله حایری میبد  \n",
       "2         NaN     اراک                          اراک  \n",
       "3         NaN   اردکان                        اردکان  \n",
       "4         NaN   ارومیه                        ارومیه  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find places coordinates manually\n",
    "getting the coordinates for the location  names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Khatam University', 'latitude': 35.7587918, 'longitude': 51.4006824}\n"
     ]
    }
   ],
   "source": [
    "def get_place_info(address, api_key):\n",
    "    # Base URL\n",
    "    base_url = \"https://maps.googleapis.com/maps/api/place/findplacefromtext/json\"\n",
    "    # Parameters in a dictionary\n",
    "    params = {\n",
    "        \"input\": address,\n",
    "        \"inputtype\": \"textquery\",\n",
    "        \"fields\": \"name,geometry\",\n",
    "        \"key\": api_key,\n",
    "    }\n",
    "    # Send request and capture response\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        # Check if there are any candidates\n",
    "        if 'candidates' in result and len(result['candidates']) > 0:\n",
    "            candidate = result['candidates'][0]  # Take the first candidate\n",
    "            name = candidate['name']\n",
    "            lat = candidate['geometry']['location']['lat']\n",
    "            lng = candidate['geometry']['location']['lng']\n",
    "            return {\"name\": name, \"latitude\": lat, \"longitude\": lng}\n",
    "        else:\n",
    "            return \"No places found in the search results.\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "api_key = \"Your_API_code"  # Replace with your actual API key\n",
    "address = \"دانشگاه غیرانتفاعی خاتم تهران\"\n",
    "place_info = get_place_info(address, api_key)\n",
    "\n",
    "print(place_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read all csv and save the outcome "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reads the csv in 100 by 100 rows and save it like that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vk/k7jt5kl12rj76cw8qmhgwd9w0000gn/T/ipykernel_19773/421553336.py:3: DeprecationWarning: Using 'method_whitelist' with Retry is deprecated and will be removed in v2.0. Use 'allowed_methods' instead\n",
      "  retry_strategy = Retry(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved 100 rows.\n",
      "Processed and saved 100 rows.\n",
      "Processed and saved 100 rows.\n",
      "Processed and saved 100 rows.\n",
      "Processed and saved 100 rows.\n",
      "Processed and saved 100 rows.\n",
      "Processed and saved 100 rows.\n",
      "Processed and saved 100 rows.\n",
      "Processed and saved 100 rows.\n",
      "Processed and saved 100 rows.\n",
      "Processed and saved 100 rows.\n",
      "Processed and saved 100 rows.\n",
      "Processed and saved 100 rows.\n",
      "Processed and saved 68 rows.\n",
      "All data processed and saved to 'updated_output_file.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Set up a session with retries and backoff\n",
    "session = requests.Session()\n",
    "retry_strategy = Retry(\n",
    "    total=3,  # Number of retries\n",
    "    backoff_factor=2,  # Wait 1, 2, 4 seconds between retries\n",
    "    status_forcelist=[429, 500, 502, 503, 504],  # Retry on these status codes\n",
    "    method_whitelist=[\"GET\"]  # Only retry on GET requests\n",
    ")\n",
    "adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "session.mount(\"https://\", adapter)\n",
    "\n",
    "# Function to get place information from Google Maps API\n",
    "def get_place_info(address, api_key):\n",
    "    base_url = \"https://maps.googleapis.com/maps/api/place/findplacefromtext/json\"\n",
    "    params = {\n",
    "        \"input\": address,\n",
    "        \"inputtype\": \"textquery\",\n",
    "        \"fields\": \"name,geometry,formatted_address,place_id,types\",\n",
    "        \"key\": api_key,\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = session.get(base_url, params=params, timeout=10)  # Timeout after 10 seconds\n",
    "        response.raise_for_status()  # Raise an error if the request failed\n",
    "        result = response.json()\n",
    "        \n",
    "        if 'candidates' in result and len(result['candidates']) > 0:\n",
    "            candidate = result['candidates'][0]\n",
    "            return {\n",
    "                \"name\": candidate.get(\"name\"),\n",
    "                \"latitude\": candidate[\"geometry\"][\"location\"][\"lat\"],\n",
    "                \"longitude\": candidate[\"geometry\"][\"location\"][\"lng\"],\n",
    "                \"formatted_address\": candidate.get(\"formatted_address\"),\n",
    "                \"place_id\": candidate.get(\"place_id\"),\n",
    "                \"types\": candidate.get(\"types\"),\n",
    "            }\n",
    "        else:\n",
    "            return {\"name\": None, \"latitude\": None, \"longitude\": None, \"formatted_address\": None, \"place_id\": None, \"types\": None}\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data for {address}: {e}\")\n",
    "        return {\"name\": None, \"latitude\": None, \"longitude\": None, \"formatted_address\": None, \"place_id\": None, \"types\": None}\n",
    "\n",
    "# Your API key\n",
    "api_key = \"Your_API_code\"  # Replace with your actual API key\n",
    "\n",
    "# File paths\n",
    "input_file = '/Users/ghost/Desktop/TeIAS/RA/RA_Map/modified_file.csv'\n",
    "output_file = \"updated_output_file.csv\"\n",
    "\n",
    "# Read the CSV file in chunks of 100 rows\n",
    "chunksize = 100\n",
    "for chunk in pd.read_csv(input_file, chunksize=chunksize):\n",
    "    # Create empty lists to store the results for the current chunk\n",
    "    names = []\n",
    "    latitudes = []\n",
    "    longitudes = []\n",
    "    formatted_addresses = []\n",
    "    place_ids = []\n",
    "    types_list = []\n",
    "\n",
    "    # Loop through the address column in the current chunk to get lat, lng, name, etc.\n",
    "    for address in chunk['full_university_name_modified']:\n",
    "        place_info = get_place_info(address, api_key)\n",
    "        names.append(place_info['name'])\n",
    "        latitudes.append(place_info['latitude'])\n",
    "        longitudes.append(place_info['longitude'])\n",
    "        formatted_addresses.append(place_info['formatted_address'])\n",
    "        place_ids.append(place_info['place_id'])\n",
    "        types_list.append(place_info['types'])\n",
    "        time.sleep(1)  # To avoid hitting the API rate limit\n",
    "\n",
    "    # Add the new columns to the current chunk DataFrame\n",
    "    chunk['place_name'] = names\n",
    "    chunk['latitude'] = latitudes\n",
    "    chunk['longitude'] = longitudes\n",
    "    chunk['formatted_address'] = formatted_addresses\n",
    "    chunk['place_id'] = place_ids\n",
    "    chunk['types'] = types_list\n",
    "\n",
    "    # Append the processed chunk to the output CSV file\n",
    "    with open(output_file, 'a') as f:\n",
    "        chunk.to_csv(f, index=False, header=f.tell() == 0)  # Add header only if the file is empty\n",
    "\n",
    "    print(f\"Processed and saved {len(chunk)} rows.\")\n",
    "\n",
    "print(f\"All data processed and saved to '{output_file}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the .csv files into .xlsx file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file with the default encoding\n",
    "input_file = \"updated_output_file.csv\"  # Change this to your input file path\n",
    "output_file = \"updated_output_file2.xlsx\"  # Change this to your desired output file path\n",
    "\n",
    "# Read the original CSV file\n",
    "df = pd.read_csv(input_file, encoding='utf-8')\n",
    "# Save the DataFrame to a new CSV file with CP-1256 encoding\n",
    "df.to_excel(output_file, index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get for the other files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a session with retries and backoff\n",
    "session = requests.Session()\n",
    "retry_strategy = Retry(\n",
    "    total=3,  # Number of retries\n",
    "    backoff_factor=2,  # Wait 1, 2, 4 seconds between retries\n",
    "    status_forcelist=[429, 500, 502, 503, 504],  # Retry on these status codes\n",
    "    method_whitelist=[\"GET\"]  # Only retry on GET requests\n",
    ")\n",
    "adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "session.mount(\"https://\", adapter)\n",
    "\n",
    "# Function to get place information from Google Maps API\n",
    "def get_place_info(address, api_key):\n",
    "    base_url = \"https://maps.googleapis.com/maps/api/place/findplacefromtext/json\"\n",
    "    params = {\n",
    "        \"input\": address,\n",
    "        \"inputtype\": \"textquery\",\n",
    "        \"fields\": \"name,geometry,formatted_address,place_id,types\",\n",
    "        \"key\": api_key,\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = session.get(base_url, params=params, timeout=10)  # Timeout after 10 seconds\n",
    "        response.raise_for_status()  # Raise an error if the request failed\n",
    "        result = response.json()\n",
    "        \n",
    "        if 'candidates' in result and len(result['candidates']) > 0:\n",
    "            candidate = result['candidates'][0]\n",
    "            return {\n",
    "                \"name\": candidate.get(\"name\"),\n",
    "                \"latitude\": candidate[\"geometry\"][\"location\"][\"lat\"],\n",
    "                \"longitude\": candidate[\"geometry\"][\"location\"][\"lng\"],\n",
    "                \"formatted_address\": candidate.get(\"formatted_address\"),\n",
    "                \"place_id\": candidate.get(\"place_id\"),\n",
    "                \"types\": candidate.get(\"types\"),\n",
    "            }\n",
    "        else:\n",
    "            return {\"name\": None, \"latitude\": None, \"longitude\": None, \"formatted_address\": None, \"place_id\": None, \"types\": None}\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data for {address}: {e}\")\n",
    "        return {\"name\": None, \"latitude\": None, \"longitude\": None, \"formatted_address\": None, \"place_id\": None, \"types\": None}\n",
    "\n",
    "# Your API key\n",
    "api_key = \"Your_API_code\"  # Replace with your actual API key\n",
    "\n",
    "# File paths\n",
    "input_file = '/Users/ghost/Desktop/TeIAS/RA/RA_Map/modified_file.csv'\n",
    "output_file = \"updated_output_file.csv\"\n",
    "\n",
    "# Read the CSV file in chunks of 100 rows\n",
    "chunksize = 100\n",
    "for chunk in pd.read_csv(input_file, chunksize=chunksize):\n",
    "    # Create empty lists to store the results for the current chunk\n",
    "    names = []\n",
    "    latitudes = []\n",
    "    longitudes = []\n",
    "    formatted_addresses = []\n",
    "    place_ids = []\n",
    "    types_list = []\n",
    "\n",
    "    # Loop through the address column in the current chunk to get lat, lng, name, etc.\n",
    "    for address in chunk['full_university_name_modified']:\n",
    "        place_info = get_place_info(address, api_key)\n",
    "        names.append(place_info['name'])\n",
    "        latitudes.append(place_info['latitude'])\n",
    "        longitudes.append(place_info['longitude'])\n",
    "        formatted_addresses.append(place_info['formatted_address'])\n",
    "        place_ids.append(place_info['place_id'])\n",
    "        types_list.append(place_info['types'])\n",
    "        time.sleep(1)  # To avoid hitting the API rate limit\n",
    "\n",
    "    # Add the new columns to the current chunk DataFrame\n",
    "    chunk['place_name'] = names\n",
    "    chunk['latitude'] = latitudes\n",
    "    chunk['longitude'] = longitudes\n",
    "    chunk['formatted_address'] = formatted_addresses\n",
    "    chunk['place_id'] = place_ids\n",
    "    chunk['types'] = types_list\n",
    "\n",
    "    # Append the processed chunk to the output CSV file\n",
    "    with open(output_file, 'a') as f:\n",
    "        chunk.to_csv(f, index=False, header=f.tell() == 0)  # Add header only if the file is empty\n",
    "\n",
    "    print(f\"Processed and saved {len(chunk)} rows.\")\n",
    "\n",
    "print(f\"All data processed and saved to '{output_file}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vk/k7jt5kl12rj76cw8qmhgwd9w0000gn/T/ipykernel_2782/535324932.py:9: DeprecationWarning: Using 'method_whitelist' with Retry is deprecated and will be removed in v2.0. Use 'allowed_methods' instead\n",
      "  retry_strategy = Retry(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data processed and saved to 'new_updated_output_file.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "import time\n",
    "\n",
    "# Set up a session with retries and backoff\n",
    "session = requests.Session()\n",
    "retry_strategy = Retry(\n",
    "    total=3,  # Number of retries\n",
    "    backoff_factor=2,  # Wait 1, 2, 4 seconds between retries\n",
    "    status_forcelist=[429, 500, 502, 503, 504],  # Retry on these status codes\n",
    "    method_whitelist=[\"GET\"]  # Only retry on GET requests\n",
    ")\n",
    "adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "session.mount(\"https://\", adapter)\n",
    "\n",
    "# Function to get place information from Google Maps API\n",
    "def get_place_info(address, api_key):\n",
    "    base_url = \"https://maps.googleapis.com/maps/api/place/findplacefromtext/json\"\n",
    "    params = {\n",
    "        \"input\": address,\n",
    "        \"inputtype\": \"textquery\",\n",
    "        \"fields\": \"name,geometry,formatted_address,place_id,types\",\n",
    "        \"key\": api_key,\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = session.get(base_url, params=params, timeout=10)  # Timeout after 10 seconds\n",
    "        response.raise_for_status()  # Raise an error if the request failed\n",
    "        result = response.json()\n",
    "        \n",
    "        if 'candidates' in result and len(result['candidates']) > 0:\n",
    "            candidate = result['candidates'][0]\n",
    "            return {\n",
    "                \"name\": candidate.get(\"name\"),\n",
    "                \"latitude\": candidate[\"geometry\"][\"location\"][\"lat\"],\n",
    "                \"longitude\": candidate[\"geometry\"][\"location\"][\"lng\"],\n",
    "                \"formatted_address\": candidate.get(\"formatted_address\"),\n",
    "                \"place_id\": candidate.get(\"place_id\"),\n",
    "                \"types\": candidate.get(\"types\"),\n",
    "            }\n",
    "        else:\n",
    "            return {\"name\": None, \"latitude\": None, \"longitude\": None, \"formatted_address\": None, \"place_id\": None, \"types\": None}\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data for {address}: {e}\")\n",
    "        return {\"name\": None, \"latitude\": None, \"longitude\": None, \"formatted_address\": None, \"place_id\": None, \"types\": None}\n",
    "\n",
    "# Your API key\n",
    "api_key = \"Your_API_code\"  # Replace with your actual API key\n",
    "\n",
    "# File paths\n",
    "input_file = '/Users/ghost/Desktop/TeIAS/RA/RA_Map/third.xlsx'\n",
    "output_file = \"new_updated_output_file.csv\"\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_excel(input_file)\n",
    "\n",
    "# Create empty lists to store the results\n",
    "names = []\n",
    "latitudes = []\n",
    "longitudes = []\n",
    "formatted_addresses = []\n",
    "place_ids = []\n",
    "types_list = []\n",
    "\n",
    "# Loop through the address column to get lat, lng, name, etc.\n",
    "for address in df['name']:\n",
    "    place_info = get_place_info(address, api_key)\n",
    "    names.append(place_info['name'])\n",
    "    latitudes.append(place_info['latitude'])\n",
    "    longitudes.append(place_info['longitude'])\n",
    "    formatted_addresses.append(place_info['formatted_address'])\n",
    "    place_ids.append(place_info['place_id'])\n",
    "    types_list.append(place_info['types'])\n",
    "    time.sleep(1)  # To avoid hitting the API rate limit\n",
    "\n",
    "# Add the new columns to the DataFrame\n",
    "df['place_name'] = names\n",
    "df['latitude'] = latitudes\n",
    "df['longitude'] = longitudes\n",
    "df['formatted_address'] = formatted_addresses\n",
    "df['place_id'] = place_ids\n",
    "df['types'] = types_list\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"All data processed and saved to '{output_file}'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
